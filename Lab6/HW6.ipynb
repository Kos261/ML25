{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework Assignment: Understanding Splitting Criteria in CART for Regression**\n",
    "---------------------\n",
    "\n",
    "In this assignment, you will explore three common formulations of the splitting criterion used in **CART (Classification and Regression Trees)** for **regression problems**:\n",
    "\n",
    "1. **Local RSS Minimization**  \n",
    "2. **RSS Gain Maximization**  \n",
    "3. **Total RSS Minimization**\n",
    "\n",
    "You will investigate whether any of these criteria are equivalent, and you will design an experiment to determine which criterion is actually employed in a standard implementation such as **scikit-learn’s DecisionTreeRegressor**.\n",
    "\n",
    "\n",
    "\n",
    "## **The Problem**\n",
    "\n",
    "Many treatments of CART for regression describe the split selection process in different ways. Below are three frequently cited formulations. Suppose we have a dataset with features $X$ and target $y$, and we seek to choose a feature $X_j$ and a threshold $t$ to split the data into two regions $R_1(X_j, t)$ and $R_2(X_j, t)$. Denote by $\\bar{y}_{R_m}$ the mean of targets within region $R_m$.\n",
    "\n",
    "1. **Local RSS Minimization**  \n",
    "   We select the feature and threshold that minimize the **sum of squared errors** in the two resulting child nodes:\n",
    "   $$\n",
    "   (X_j^*, t^*) = \\arg\\min_{X_j, t} \\sum_{m=1}^{2} \\sum_{i : x_i \\in R_m(X_j, t)} (y_i - \\bar{y}_{R_m})^2.\n",
    "   $$\n",
    "\n",
    "2. **RSS Gain Maximization**  \n",
    "\n",
    "   It is also a local method, looking only at a parent and two child nodes.\n",
    "\n",
    "   We select the feature and threshold that maximize the **reduction** in RSS, computed by subtracting the RSS of the two child nodes from the RSS in the parent node:\n",
    "   $$\n",
    "   (X_j^*, t^*) = \\arg\\max_{X_j, t} \\Bigl\\{\n",
    "   \\underbrace{\\sum_{i : x_i \\in \\text{Parent}} (y_i - \\bar{y})^2}_{\\text{Parent RSS}}\n",
    "   \\;-\\;\n",
    "   \\underbrace{\\sum_{m=1}^{2} \\sum_{i : x_i \\in R_m(X_j, t)} (y_i - \\bar{y}_{R_m})^2}_{\\text{Children RSS}}\n",
    "   \\Bigr\\}.\n",
    "   $$\n",
    "\n",
    "3. **Total RSS Minimization**  \n",
    "   For a dataset $\\{(x_i, y_i)\\}_{i=1}^N$ with features $X$ and target $y$, let $T$ be the current tree.\n",
    "\n",
    "   For any split on feature $X_j$ at threshold $t$, define $T(X_j, t)$ as the new tree obtained by splitting one leaf of $T$ into two leaves $R_1(X_j, t)$ and $R_2(X_j, t)$.\n",
    "   \n",
    "   Let $\\mathrm{Leaves}(T(X_j, t))$ be the set of all leaf indices in this new tree. For each leaf $m \\in \\mathrm{Leaves}(T(X_j, t))$, define:\n",
    "   $$\n",
    "   R_m = \\{\\, i \\,\\mid\\, x_i \\text{ ends in leaf } m\\}.\n",
    "   $$\n",
    "\n",
    "   $R_m$ set collects all data indices $i$ whose feature vector $x_i$ is classified into the leaf node $m$ when passed through the tree $T(X_j,t)$. In other words, each leaf node $m$ in $T(X_j, t)$ corresponds to a unique path of splits, and any data point $x_i$ that follows that path is assigned to the leaf $m$; hence, it belongs to $R_m$.\n",
    "\n",
    "   $R_m$ sets for all leafs $m \\in \\mathrm{Leaves}(T(X_j, t))$ define a partition of all indices.\n",
    "\n",
    "   Then the objective of **minimizing total Residual Sum of Squares (total RSS)** is stated as:\n",
    "   $$\n",
    "   (X_j^*, t^*) = \\arg\\min_{(X_j, t)} \\sum_{m \\in \\mathrm{Leaves}(T(X_j, t))}\n",
    "   \\sum_{i \\in R_m} \\Bigl(y_i - \\overline{y}_{R_m}\\Bigr)^2,\n",
    "   $$\n",
    "   where\n",
    "   $$\n",
    "   \\overline{y}_{R_m} = \\frac{1}{\\lvert R_m \\rvert}\n",
    "   \\sum_{i \\in R_m} y_i\n",
    "   $$\n",
    "   is the mean response in leaf $m$.\n",
    "\n",
    "\n",
    "## **Research Questions**\n",
    "\n",
    "1. **Equivalence Analysis**  \n",
    "   Determine whether the above formulations are equivalent or if they can yield different split choices. Specifically:\n",
    "   - Are *local RSS minimization* and *RSS gain maximization* equivalent?\n",
    "   - Does *total RSS minimization* coincide with either of these two, or is it distinct?\n",
    "   \n",
    "2. **Empirical Experiment**  \n",
    "   Design and conduct a Python experiment to determine which of these formulations is implemented in `scikit-learn` in `DecisionTreeRegressor`. Present numerical results and plots to support your conclusion.\n",
    "\n",
    "\n",
    "## **Tasks & Deliverables**\n",
    "\n",
    "1. **Formulation Analysis**  \n",
    "   - Compare *local RSS minimization*, *RSS gain maximization*, and *total RSS minimization*.\n",
    "   - If you find that any pair of formulations is equivalent, provide a concise proof.  \n",
    "   - If you find that they differ, construct a counterexample.\n",
    "\n",
    "2. **Empirical Verification**  \n",
    "   - Create a small artificial dataset and train a `DecisionTreeRegressor` from `scikit-learn`.\n",
    "   - The dataset must be designed in a way that uniquely identifies the formulation used. Provide a short code snippet and a plot or table to support your conclusion.\n",
    "\n",
    "3. **Report**  \n",
    "   - Summarize your theoretical insights and empirical findings in a **Colab notebook**.\n",
    "   - Include the relevant proofs, code, discussion, and conclusions.\n",
    "   - Place the notebook in your **GitHub repository** for this course, add a link to it in your README.md and add an **“Open in Colab”** badge in the notebook so it can be launched directly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "We split parent into two regions $R_1$ and $R_2$\n",
    "\n",
    "$RSS_{parent} = \\sum_{y_i \\in parent} (y_i - \\bar{y})^2$\n",
    "\n",
    "$RSS_{children} = \\sum_{y_i \\in R_{1}} (y_i - \\bar{y}_{R_{1}})^2 + \\sum_{y_i \\in R_{2}} (y_i - \\bar{y}_{R_2})^2 $\n",
    "\n",
    "$RSS_{GAIN} = RSS_{parent} - RSS_{children}$    \n",
    "\n",
    "\n",
    "**Total RSS**\n",
    "Ex. Two leaves $A$ and $B$. Split $B$ into  $B_1$ and $B_2$\n",
    "\n",
    "1) $RSS_{total} = RSS(A) + RSS(B)$\n",
    "2) $RSS_{total} = RSS(A) + RSS(B_1) + RSS(B_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER 1\n",
    "Maxxing $RSS_{GAIN}$ when $RSS_{parent}$ is fixed (because it doesn't depend on treshold and chosen feature) means minimazing $RSS_{children}$ which means *local RSS minimization* and *RSS gain maximization* are equivalent.\n",
    "\n",
    "\n",
    "Total RSS is similar to other two when we calculate only current split and not any other splits. First two methods are **greedy** and do not track history.\n",
    "\n",
    "# Counterexample: When TOTAL RSS and LOCAL RSS Differ\n",
    "\n",
    "## Data\n",
    "We have 5 data points with values:\n",
    "$$(x_1,y_1 = 1), (x_2,y_2 = 2), (x_3,y_3 = 5), (x_4,y_4 = 5), (x_5,y_5 = 5)$$\n",
    "\n",
    "## Initial Split\n",
    "```\n",
    "       [Root Split]\n",
    "         X0 < 5\n",
    "        /       \\\n",
    "   Leaf A      Leaf B\n",
    "```\n",
    "\n",
    "- **Leaf A**: $\\{(x_1,y_1),(x_2,y_2)\\}$\n",
    "- **Leaf B**: $\\{(x_3,y_3), (x_4,y_4), (x_5,y_5)\\}$\n",
    "\n",
    "## Initial RSS Calculations\n",
    "- $\\bar y_A = \\frac{1+2}{2} = 1.5$\n",
    "- $RSS(A) = (1-1.5)^2 + (2-1.5)^2 = 0.25 + 0.25 = 0.5$\n",
    "- $RSS(B) = 0$ (all predictions match perfectly)\n",
    "- $RSS_{total} = 0.5 + 0 = 0.5$\n",
    "\n",
    "## Option 1: Split Leaf A\n",
    "\n",
    "- $A_1: (x_1,y_1=1)$ with $\\bar y_{A_1} = 1$, $RSS(A_1) = 0$\n",
    "- $A_2: (x_2,y_2=2)$ with $\\bar y_{A_2} = 2$, $RSS(A_2) = 0$\n",
    "- **Result**: $RSS_{total} = 0 + 0 + 0 = 0$\n",
    "\n",
    "## Option 2: Split Leaf B\n",
    "- $B_1: (x_3,y_3=5),(x_4,y_4=5)$ with $\\bar y_{B_1} = 5$, $RSS(B_1) = 0$\n",
    "- $B_2: (x_5,y_5=5)$ with $\\bar y_{B_2} = 5$, $RSS(B_2) = 0$\n",
    "- **Result**: $RSS_{total} = 0.5 + 0 + 0 = 0.5$\n",
    "\n",
    "## Key Observations\n",
    "| Metric          | Split Leaf A | Split Leaf B |\n",
    "|-----------------|--------------|--------------|\n",
    "| Local RSS Gain  | 0.5          | 0            |\n",
    "| Total RSS Gain  | 0.5 -> 0     | 0.5 -> 0.5   |\n",
    "\n",
    "This shows:\n",
    "1. **Local RSS** suggests only Leaf A offers improvement (0.5 gain)\n",
    "2. **Total RSS** reveals that splitting Leaf A gives global improvement (0.5 -> 0)\n",
    "3. Splitting Leaf B appears useless by local RSS, but might contain informative splits when considering feature interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMPIRICAL EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UWvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
